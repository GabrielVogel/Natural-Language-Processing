{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ['The quick brown fox jumps over the lazy dog', 'I like my dog', 'I like my cat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'START': 0,\n",
       " 'END': 1,\n",
       " 'the': 2,\n",
       " 'quick': 3,\n",
       " 'brown': 4,\n",
       " 'fox': 5,\n",
       " 'jumps': 6,\n",
       " 'over': 7,\n",
       " 'lazy': 8,\n",
       " 'dog': 9,\n",
       " 'i': 10,\n",
       " 'like': 11,\n",
       " 'my': 12,\n",
       " 'cat': 13}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index = {'START':0, 'END':1}\n",
    "index2word = {0:'START', 1:'END'}\n",
    "\n",
    "\n",
    "i = 2\n",
    "for sentence in text:\n",
    "    for word in sentence.split():\n",
    "        token = word.lower()\n",
    "        if token not in word2index:\n",
    "            word2index[token] = i\n",
    "            index2word[i] = token\n",
    "            i += 1\n",
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[2, 3, 4, 5, 6, 7, 2, 8, 9], [10, 11, 12, 9], [10, 11, 12, 13]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = len(word2index)\n",
    "##Add one smoothing\n",
    "bigram_probs = np.ones((V,V))\n",
    "\n",
    "\n",
    "tokenized = [[word2index[word.lower()] for word in sentence.split()] for sentence in text]\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\Large p(W_t|W_{t-1}) = \\frac{count(W_{t-1}W_t) + \\alpha}{count(W_{t-1}) + \\alpha V} $$ com $V$ sendo o tamanho do vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in tokenized:\n",
    "    for i in range(len(sentence)):\n",
    "        if i == 0:\n",
    "            bigram_probs[0, sentence[i]] += 1\n",
    "            \n",
    "        elif i == len(sentence) - 1:\n",
    "            bigram_probs[sentence[i], 1] += 1\n",
    "            \n",
    "        else:\n",
    "            bigram_probs[sentence[i-1], sentence[i]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Normalize sentences\n",
    "bigram_probs /= bigram_probs.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Medida usando log para testar o quanto uma frase é verdadeira baseada no corpus utilizado. Dividindo pelo tamanho da frase para normalizar o valor.\n",
    "\n",
    "\n",
    "$$\\Large \\frac{1}{T} [\\log(w_1) + \\sum_{t=2}^T \\log(w_t | w_{t-1})]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Score \n",
    "\n",
    "def score(tokenized_sentence):\n",
    "    s = 0\n",
    "    for i in range(len(tokenized_sentence)):\n",
    "        if i == 0:\n",
    "            s += np.log(bigram_probs[0, tokenized_sentence[i]])\n",
    "        else:\n",
    "            s += np.log(bigram_probs[tokenized_sentence[i-1], tokenized_sentence[i]])\n",
    "    \n",
    "    s += np.log(bigram_probs[sentence[-1], 1])\n",
    "    return s / len(tokenized_sentence + 1)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
